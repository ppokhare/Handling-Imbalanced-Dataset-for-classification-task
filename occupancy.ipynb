{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "import re\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#for scaling the data\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "#for oversampling to create a balanced train set\n",
    "from sklearn.utils import resample\n",
    "#for spliting data into traning and testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#for Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#for Support Vector Machine\n",
    "from sklearn.svm import SVC\n",
    "#for KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "#for decision tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "#for random forest and boosting\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "\n",
    "#for metrics\n",
    "from sklearn.metrics import f1_score\n",
    "#from sklearn.metrics import accuracy_score, roc_auc_score,f1_score, precision_score, recall_score,classification_report,confusion_matrix\n",
    "\n",
    "#PCA for Dimension Reduction\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "#to perform cross validation\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the sense of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 20560 entries, 1 to 2804\n",
      "Data columns (total 6 columns):\n",
      "Temperature      20560 non-null float64\n",
      "Humidity         20560 non-null float64\n",
      "Light            20560 non-null float64\n",
      "CO2              20560 non-null float64\n",
      "HumidityRatio    20560 non-null float64\n",
      "Occupancy        20560 non-null int64\n",
      "dtypes: float64(5), int64(1)\n",
      "memory usage: 1.1 MB\n"
     ]
    }
   ],
   "source": [
    "#Load the data\n",
    "df1 = pd.read_csv('datatest.txt',delimiter=\",\")\n",
    "df2 = pd.read_csv('datatest2.txt',delimiter=\",\")\n",
    "df3 = pd.read_csv('datatraining.txt',delimiter=\",\")\n",
    "df = [df3,df2,df1]\n",
    "df = pd.concat(df)\n",
    "df = df.drop(\"date\",1)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4750\n",
      "15810\n"
     ]
    }
   ],
   "source": [
    "print(df[\"Occupancy\"].value_counts()[1])\n",
    "print(df[\"Occupancy\"].value_counts()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Occupited status: 23.103112840466927 %\n",
      "Not occupited status: 76.89688715953308 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Actual Raw Data: Very unbalanced')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "occupied = (df[\"Occupancy\"].value_counts()[1]/len(df))*100\n",
    "not_occupied = (df[\"Occupancy\"].value_counts()[0]/len(df))*100\n",
    "\n",
    "print(\"Occupited status:\",occupied,\"%\")\n",
    "print(\"Not occupited status:\", not_occupied,\"%\")\n",
    "\n",
    "#frequency graph of unbalaced data\n",
    "sns.countplot(\"Occupancy\",data=df).set_title('Actual Raw Data: Very unbalanced')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see how unbalanced our data is. There are very low number of occupied status class incompare to not occupied class (4750 VS 15810) Most of the out box classifiers from Scikit-Learn are designed to minimize error loss function (which will maximize accuracy. If we have our classifier to just classify everything to 0, then we can easily obtain the accuracy of than 76.89% but that's not a faithful. So, we have to use different robust metrics like F-score and introduce bias in samlping process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get X and Y vector\n",
    "X = df.drop(\"Occupancy\",1)\n",
    "Y = df[\"Occupancy\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resampling Techniques: Oversampling\n",
    "Here we are going to oversample the least occuring class which is occupied status class. \n",
    "Oversampling introducing a bais to select more samples from occupied status class than from not occupied status class. This is done to compensate for an imblanced in the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oversample(X_train,Y_train):\n",
    "    #now add training set back together\n",
    "    X = pd.concat([X_train,Y_train],1)\n",
    "    #print(train_concat[\"class\"])\n",
    "\n",
    "    #seperate non-pulsar and pulsar class\n",
    "    occupied = X[X[\"Occupancy\"] == 1]\n",
    "    not_occupied  = X[X[\"Occupancy\"] == 0]\n",
    "\n",
    "    #use resample to create 283823 \"fake/duplicate\"  data\n",
    "    occupiedResampled = resample(occupied, replace = True, n_samples = len(not_occupied))\n",
    "\n",
    "    allResampled = pd.concat([not_occupied,occupiedResampled])\n",
    "    #print(allResampled.shape)\n",
    "\n",
    "    #training set ready after resampling\n",
    "    X_train = allResampled.drop(\"Occupancy\",1)\n",
    "    Y_train = allResampled[\"Occupancy\"]\n",
    "\n",
    "    #frequency graph of unbalaced data\n",
    "    #sns.countplot(\"Class\",data=allResampled).set_title('training set after oversampling')\n",
    "\n",
    "    return X_train,Y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our training set looks much balanced now after oversampling occupied status class!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparamaters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for log Reg\n",
    "Penalty_list = [ 'l1', 'l2']\n",
    "C_list = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "logReg_param_grid = {'penalty': Penalty_list, 'C': C_list}\n",
    "\n",
    "#for SVM\n",
    "C_list = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "Gamma_list = [1e-6,1e-5,1e-4,1e-3,1e-2]\n",
    "Kernel_list= ['linear', 'rbf', 'poly', 'sigmoid']\n",
    "svm_param_grid = {'C':C_list, 'kernel': Kernel_list, 'gamma' : Gamma_list}\n",
    "\n",
    "#KNN \n",
    "K_list = [1, 3, 5, 7, 9]\n",
    "Algorithm_list = ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "knn_param_grid = {'n_neighbors': K_list, 'algorithm': Algorithm_list}\n",
    "\n",
    "#Decision Tree \n",
    "Criterion_list = ['gini', 'entropy']\n",
    "D_list = [1,2,3,4,5]\n",
    "decisionTree_param_grid = {'max_depth': D_list, 'criterion': Criterion_list}\n",
    "\n",
    "#Random Forest \n",
    "numberOfTree_list = [5,10,50,100,500,1000,5000,10000]\n",
    "Criterion_list = ['gini', 'entropy']\n",
    "randomForest_param_grid = {'n_estimators': numberOfTree_list, 'criterion': Criterion_list}\n",
    "\n",
    "#AdaBoost\n",
    "n_estimators_list = [10,50,100,500]\n",
    "learningRate_list = [0.0001,0.001,0.01,0.1,1.0]\n",
    "adaBoost_param_grid = {'n_estimators': n_estimators_list, 'learning_rate': learningRate_list}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare models\n",
    "# models = [id name, classifier, hypermater of the classifier for Cross Validation]\n",
    "models = []\n",
    "models.append(('Logistic Regression', LogisticRegression(),logReg_param_grid))\n",
    "models.append(('K-nearest Neighbors', KNeighborsClassifier(),knn_param_grid ))\n",
    "models.append(('Decision Tree', DecisionTreeClassifier(),decisionTree_param_grid))\n",
    "models.append(('Random Forest', RandomForestClassifier(),randomForest_param_grid))\n",
    "models.append(('AdaBoost', AdaBoostClassifier(),adaBoost_param_grid))\n",
    "models.append(('Support Vector Machine', SVC(max_iter = 10000),svm_param_grid ))\n",
    "#print(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8 µs, sys: 0 ns, total: 8 µs\n",
      "Wall time: 14.5 µs\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "def train_model(result,name,model,hyperparam):\n",
    "    \n",
    "    trainingErrorForRepeats = []\n",
    "    testingErrorForRepeats = []\n",
    "    #run 3 times and obtain mean and standard devation of training/testing error\n",
    "    for repeat in range(3):\n",
    "        #find optimal combination of hyperaramaters\n",
    "        grid_search = GridSearchCV(estimator=model,param_grid=hyperparam,cv=5)\n",
    "        grid_search.fit(X_train,Y_train)\n",
    "        \n",
    "        #Find optimal hyper-paramater\n",
    "        best_hyperparam = grid_search.best_params_\n",
    "    \n",
    "        #trainng f1 score\n",
    "        y_prediction_train = grid_search.best_estimator_.predict(X_train)\n",
    "        train_error_f1 = f1_score(Y_train,y_prediction_train)\n",
    "       \n",
    "        #testing f1 score\n",
    "        y_prediction_test = grid_search.best_estimator_.predict(X_test)\n",
    "        test_error_f1 = f1_score(Y_test,y_prediction_test)\n",
    "        \n",
    "        trainingErrorForRepeats.append(train_error_f1)\n",
    "        testingErrorForRepeats.append(test_error_f1)\n",
    "        \n",
    "    trainMean = np.mean(trainingErrorForRepeats)\n",
    "    trainMean = round((trainMean*100),2)\n",
    "    trainStd = np.std(trainingErrorForRepeats)\n",
    "    trainStd = round((trainStd*100),2)\n",
    "    trainError = str(trainMean) + u\"\\u00B1\"+ str(trainStd)\n",
    "   \n",
    "    testMean = np.mean(testingErrorForRepeats)\n",
    "    testMean = round((testMean*100),2)\n",
    "    testStd = np.std(testingErrorForRepeats)\n",
    "    testStd = round((testStd*100),2)\n",
    "    testError = str(testMean) + u\"\\u00B1\"+ str(testStd)\n",
    "    \n",
    "    #toAdd = [name, best_hyperparam, train_error, test_error]\n",
    "    toAdd = [name, best_hyperparam, trainError, testError]\n",
    "    result.append(toAdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now training  Logistic Regression in train size 0.2\n",
      "Logistic Regression  done in  12.657613999999999\n",
      "now training  K-nearest Neighbors in train size 0.2\n",
      "K-nearest Neighbors  done in  133.67795999999998\n",
      "now training  Decision Tree in train size 0.2\n",
      "Decision Tree  done in  1.3222230000000081\n",
      "now training  Random Forest in train size 0.2\n",
      "Random Forest  done in  1849.746318\n",
      "now training  AdaBoost in train size 0.2\n",
      "AdaBoost  done in  193.8849949999999\n",
      "now training  Support Vector Machine in train size 0.2\n",
      "Support Vector Machine  done in  792.7342350000004\n",
      "now training  Logistic Regression in train size 0.8\n",
      "Logistic Regression  done in  314.0893109999997\n",
      "now training  K-nearest Neighbors in train size 0.8\n",
      "K-nearest Neighbors  done in  459.71445300000005\n",
      "now training  Decision Tree in train size 0.8\n",
      "Decision Tree  done in  3.503157999999985\n",
      "now training  Random Forest in train size 0.8\n",
      "Random Forest  done in  7916.599225999999\n",
      "now training  AdaBoost in train size 0.8\n",
      "AdaBoost  done in  596.9992629999997\n",
      "now training  Support Vector Machine in train size 0.8\n",
      "Support Vector Machine  done in  8529.875168000002\n"
     ]
    }
   ],
   "source": [
    "#REAL MEAT\n",
    "\n",
    "#Split it into train and test\n",
    "train_size = [0.2,0.8]\n",
    "#results\n",
    "result = []\n",
    "for size in train_size:\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X,Y, train_size=size)\n",
    "    X_train, Y_train = oversample(X_train,Y_train)\n",
    "    for name, model, hyperparam in models:\n",
    "        print(\"now training \" , name,\"in train size\", size)\n",
    "        start = time.clock()\n",
    "        train_model(result,name,model,hyperparam)\n",
    "        end = time.clock()\n",
    "        print(name, \" done in \", end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Logistic Regression', {'C': 0.1, 'penalty': 'l1'}, '99.13±0.0', '97.4±0.01'], ['K-nearest Neighbors', {'algorithm': 'auto', 'n_neighbors': 1}, '100.0±0.0', '96.53±0.0'], ['Decision Tree', {'criterion': 'gini', 'max_depth': 4}, '99.51±0.0', '97.62±0.01'], ['Random Forest', {'criterion': 'entropy', 'n_estimators': 10}, '99.95±0.04', '97.69±0.03'], ['AdaBoost', {'learning_rate': 1.0, 'n_estimators': 500}, '100.0±0.0', '97.32±0.0'], ['Support Vector Machine', {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}, '99.84±0.0', '96.49±0.0'], ['Logistic Regression', {'C': 0.01, 'penalty': 'l1'}, '99.19±0.0', '97.11±0.0'], ['K-nearest Neighbors', {'algorithm': 'auto', 'n_neighbors': 1}, '100.0±0.0', '97.15±0.0'], ['Decision Tree', {'criterion': 'entropy', 'max_depth': 5}, '99.4±0.0', '97.14±0.0'], ['Random Forest', {'criterion': 'entropy', 'n_estimators': 100}, '100.0±0.0', '98.24±0.09'], ['AdaBoost', {'learning_rate': 1.0, 'n_estimators': 500}, '99.31±0.0', '97.2±0.0'], ['Support Vector Machine', {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}, '99.8±0.0', '97.11±0.0']]\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print(df):\n",
    "    return display(HTML(df.to_html().replace(\"\\\\n\",\"<br>\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training size: 20%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Optimal Hyper-paramater</th>\n",
       "      <th>Training F1 SCore</th>\n",
       "      <th>Testing F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l1'}</td>\n",
       "      <td>99.13±0.0</td>\n",
       "      <td>97.4±0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>K-nearest Neighbors</td>\n",
       "      <td>{'algorithm': 'auto', 'n_neighbors': 1}</td>\n",
       "      <td>100.0±0.0</td>\n",
       "      <td>96.53±0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 4}</td>\n",
       "      <td>99.51±0.0</td>\n",
       "      <td>97.62±0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'criterion': 'entropy', 'n_estimators': 10}</td>\n",
       "      <td>99.95±0.04</td>\n",
       "      <td>97.69±0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>{'learning_rate': 1.0, 'n_estimators': 500}</td>\n",
       "      <td>100.0±0.0</td>\n",
       "      <td>97.32±0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>{'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}</td>\n",
       "      <td>99.84±0.0</td>\n",
       "      <td>96.49±0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training size: 80%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Optimal Hyper-paramater</th>\n",
       "      <th>Training F1 SCore</th>\n",
       "      <th>Testing F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 0.01, 'penalty': 'l1'}</td>\n",
       "      <td>99.19±0.0</td>\n",
       "      <td>97.11±0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>K-nearest Neighbors</td>\n",
       "      <td>{'algorithm': 'auto', 'n_neighbors': 1}</td>\n",
       "      <td>100.0±0.0</td>\n",
       "      <td>97.15±0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5}</td>\n",
       "      <td>99.4±0.0</td>\n",
       "      <td>97.14±0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'criterion': 'entropy', 'n_estimators': 100}</td>\n",
       "      <td>100.0±0.0</td>\n",
       "      <td>98.24±0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>{'learning_rate': 1.0, 'n_estimators': 500}</td>\n",
       "      <td>99.31±0.0</td>\n",
       "      <td>97.2±0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>{'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}</td>\n",
       "      <td>99.8±0.0</td>\n",
       "      <td>97.11±0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#strip result into multiple based on what it refeers to\n",
    "\n",
    "modelNameResult = []\n",
    "bestHyperparamaterResult = []\n",
    "trainingErrorResult = []\n",
    "testingErrorResult = []\n",
    "\n",
    "for row in result:\n",
    "    modelNameResult.append(row[0])\n",
    "    bestHyperparamaterResult.append(row[1])\n",
    "    trainingErrorResult.append(row[2])\n",
    "    testingErrorResult.append(row[3])\n",
    "\n",
    "tempDataframe = pd.DataFrame({'Classifier':modelNameResult,\n",
    "                          'Optimal Hyper-paramater':bestHyperparamaterResult,\n",
    "                          'Training F1 SCore':trainingErrorResult,\n",
    "                          'Testing F1 Score':testingErrorResult })\n",
    "\n",
    "train20Dataframe = tempDataframe[0:6]\n",
    "train80Dataframe = tempDataframe[6:12]\n",
    "\n",
    "#pretty_print(tempDataframe)\n",
    "print(\"training size: 20%\")\n",
    "pretty_print(train20Dataframe)\n",
    "print(\"training size: 80%\")\n",
    "pretty_print(train80Dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempDataframe.to_csv('occupancy_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25318, 5)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}